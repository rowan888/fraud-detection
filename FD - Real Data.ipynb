{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f9720-8a83-4703-8877-6679a2a90fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd            \n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns                  \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.pipeline import make_pipeline  \n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance, to_graphviz\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657eff39-b05a-4d4b-9cf3-1a5c2ec42220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7b5f3-063d-44f7-b922-d896ac0c48d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1d022-bdc5-4bfe-a41b-52d2bf098eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950901a6-182f-4615-b3b5-511939d498e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "d = df.corr()['Class'][:-1].abs().sort_values().plot(kind='bar', title='Most correlated features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a55e8-742d-4f3f-b691-f0a754459e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x='V17', y='V14',hue='Class', data=df, palette = 'dark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62deed53-26f3-4d19-a4a2-4ed63abf9dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "fraud_cases = df[df['Class'] == 1]\n",
    "non_fraud_cases = df[df['Class'] == 0]\n",
    "\n",
    "num_non_fraud = int(len(non_fraud_cases) * 0.20)\n",
    "\n",
    "non_fraud_sample = non_fraud_cases.sample(n=num_non_fraud, random_state=42)\n",
    "\n",
    "df_new = pd.concat([fraud_cases, non_fraud_sample], axis=0)\n",
    "\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_top3 = df_new[['V17', 'V14', 'V12']]\n",
    "\n",
    "fig = px.scatter_3d(X_top3, x='V17', y='V14', z='V12', color=df_new['Class'], color_discrete_sequence=['red', 'green'])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='V17',\n",
    "        yaxis_title='V14',\n",
    "        zaxis_title='V12',\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='Interactive 3D Scatter Plot of Top 3 Principal Components (20% Non-Fraud Cases)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66572c3-5d50-4537-af60-ce92b4c0f16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fraud_cases = df[df['Class'] == 1]\n",
    "non_fraud_cases = df[df['Class'] == 0]\n",
    "\n",
    "num_non_fraud = int(len(non_fraud_cases) * 0.20)\n",
    "\n",
    "non_fraud_sample = non_fraud_cases.sample(n=num_non_fraud, random_state=42)\n",
    "\n",
    "df_new = pd.concat([fraud_cases, non_fraud_sample], axis=0)\n",
    "\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_top3 = df_new[['V25', 'V15', 'V13']]\n",
    "\n",
    "fig = px.scatter_3d(X_top3, x='V25', y='V15', z='V13', color=df_new['Class'], color_discrete_sequence=['red', 'green'])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='V25',\n",
    "        yaxis_title='V15',\n",
    "        zaxis_title='V13',\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='Interactive 3D Scatter Plot of Bottom 3 Principal Components (20% Non-Fraud Cases)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249e445-9d6e-4803-8cc9-d0a360d73baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "fraud_cases = df[df['Class'] == 1]\n",
    "non_fraud_cases = df[df['Class'] == 0]\n",
    "\n",
    "num_non_fraud = int(len(non_fraud_cases) * 0.20)\n",
    "\n",
    "non_fraud_sample = non_fraud_cases.sample(n=num_non_fraud, random_state=42)\n",
    "\n",
    "df_new = pd.concat([fraud_cases, non_fraud_sample], axis=0)\n",
    "\n",
    "df_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X = df_new[['V25', 'V15', 'V13']]\n",
    "y = df_new['Class']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "df_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(df_resampled['Class'].value_counts())\n",
    "\n",
    "fig = px.scatter_3d(df_resampled, x='V25', y='V15', z='V13', color='Class', color_discrete_sequence=['red', 'green'])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='V25',\n",
    "        yaxis_title='V15',\n",
    "        zaxis_title='V13',\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title='Interactive 3D Scatter Plot of Bottom 3 Principal Components (SMOTE Applied)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c6913-7022-4973-876b-49b0e5840306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Duplicated values dropped succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71ff48-62ad-416f-8e70-26992a28dcb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop('Time', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda9bf6-4730-43ee-b6c5-07303e75cacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_columns = (list(df.loc[:, 'V1':'Amount']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953251e8-941b-4f89-bc66-8c7027647670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxplots_custom(dataset, columns_list, rows, cols, suptitle):\n",
    "    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(16,25))\n",
    "    fig.suptitle(suptitle,y=1, size=25)\n",
    "    axs = axs.flatten()\n",
    "    for i, data in enumerate(columns_list):\n",
    "        sns.boxplot(data=dataset[data], orient='h', ax=axs[i])\n",
    "        axs[i].set_title(data + ', skewness is: '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n",
    "        \n",
    "boxplots_custom(dataset=df, columns_list=numeric_columns, rows=10, cols=3, suptitle='Boxplots for each variable')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a22d56-9fa4-4ebf-8064-a4dcd9dfaf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already loaded the dataset into a DataFrame called 'df'\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# Calculate the precision-recall curve and AUC-PRC\n",
    "y_prob = dt_classifier.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUC-PRC:\", auc_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208efa2-7016-4c47-9634-2bb67e625449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Search CV\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Random Search CV\n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_grid, n_iter=1, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the F1 score of the best model\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# Calculate the precision-recall curve and AUC-PRC of the best model\n",
    "y_prob = best_rf_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUC-PRC:\", auc_prc)\n",
    "\n",
    "\n",
    "rf_prob = y_prob \n",
    "rf_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f102f-0bf5-4ecd-b939-b4d987ea5f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300bc2d-8401-4794-8e80-94a808fcd048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4a9cd-3c09-41da-a8fa-6cfab900bbd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "importances = best_rf_model.feature_importances_\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "imp_df = imp_df.sort_values('Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(imp_df['Feature'], imp_df['Importance'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Gini Importance')\n",
    "plt.title('Feature Importance based on Gini Impurity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d246d5-0e44-4bfa-9739-f84300cd7d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape the data for LSTM input\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(X_reshaped) * 0.8)\n",
    "X_train, X_test = X_reshaped[:train_size], X_reshaped[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, X_scaled.shape[1])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_prob = model.predict(X_test)\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the F1 score of the model\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# Calculate the precision-recall curve and AUC-PRC of the model\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUC-PRC:\", auc_prc)\n",
    "\n",
    "lstm_prob = y_prob \n",
    "lstm_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4ef70-3ff6-403d-8154-46892e187b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "# Combine the predictions using majority voting\n",
    "ensemble_pred = np.round((lstm_pred + rf_pred) / 2).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "print(\"Ensemble Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the F1 score of the ensemble model\n",
    "f1 = f1_score(y_test, ensemble_pred)\n",
    "print(\"Ensemble F1 score:\", f1)\n",
    "\n",
    "# Calculate the precision-recall curve and AUC-PRC of the ensemble model\n",
    "ensemble_prob = (lstm_prob.ravel() + rf_prob.ravel()) / 2\n",
    "precision, recall, _ = precision_recall_curve(y_test, ensemble_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"Ensemble AUC-PRC:\", auc_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21015b4b-656a-4a6d-a2af-8f52af993dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "y_prob = dt_classifier.predict_proba(X_test)[:, 1]  \n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUC-PRC:\", auc_prc)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_classifier, filled=True, rounded=True, class_names=[\"0\", \"1\"], feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d312a3b-22fa-4ee9-8d49-05721fd557f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b163c37-32ee-453e-8c89-60342ddfe25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming you have already loaded the dataset into a DataFrame called 'df'\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a variable to control the use of SMOTE\n",
    "use_smote = True\n",
    "\n",
    "# Apply SMOTE to the training data if use_smote is True\n",
    "if use_smote:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for Random Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform Random Search\n",
    "random_search = RandomizedSearchCV(estimator=gb_classifier, param_distributions=param_grid, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_gb_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the F1 score of the best model\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# Calculate the precision-recall curve and AUC-PRC of the best model\n",
    "y_prob = best_gb_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUC-PRC:\", auc_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7a39f-be1f-4b8e-abae-e0569a69ef30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "# Assuming you have already loaded the dataset into a DataFrame called 'df'\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform Random Search\n",
    "random_search = RandomizedSearchCV(estimator=gb_classifier, param_distributions=param_grid, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_gb_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the best model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the F1 score of the best model\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 score:\", f1)\n",
    "\n",
    "# Calculate the precision-recall curve and AUC-PRC of the best model\n",
    "y_prob = best_gb_model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUC-PRC:\", auc_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1664ac-60c1-4d2d-8bc9-991170a4d702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
