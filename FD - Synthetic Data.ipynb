{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data preprocessing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "# Model\n",
    "from scipy.stats import skew\n",
    "import yellowbrick\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Config\n",
    "mpl.rcParams['font.family'] = 'monospace' \n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "plotly.offline.init_notebook_mode() \n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading csv files and drop the first column\n",
    "df_train = pd.read_csv('fraudTrain.csv')\n",
    "df_train.drop(df_train.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_test = pd.read_csv('fraudTest.csv')\n",
    "df_test.drop(df_test.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# First view 10 rows\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.rename(columns={\"trans_date_trans_time\":\"transaction_time\",\n",
    "                         \"cc_num\":\"credit_card_number\",\n",
    "                         \"amt\":\"amount(usd)\",\n",
    "                         \"trans_num\":\"transaction_id\"},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[\"transaction_time\"] = pd.to_datetime(df_train[\"transaction_time\"], infer_datetime_format=True)\n",
    "df_train[\"dob\"] = pd.to_datetime(df_train[\"dob\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Apply function utcfromtimestamp and drop column unix_time\n",
    "df_train['time'] = df_train['unix_time'].apply(datetime.utcfromtimestamp)\n",
    "df_train.drop('unix_time', axis=1)\n",
    "\n",
    "# Add cloumn hour of day\n",
    "df_train['hour_of_day'] = df_train.time.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[['time','hour_of_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change dtypes\n",
    "df_train.credit_card_number = df_train.credit_card_number.astype('category')\n",
    "df_train.is_fraud = df_train.is_fraud.astype('category')\n",
    "df_train.hour_of_day = df_train.hour_of_day.astype('category')\n",
    "\n",
    "# Check\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.round(df_train.describe(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = [pd.Grouper(key=\"transaction_time\", freq=\"1W\"), \"is_fraud\"]\n",
    "df_ = df_train.groupby(by=groups).agg({\"amount(usd)\":'mean',\"transaction_id\":\"count\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_traces(df, x, y,hue, mode, cmap, showlegend=None):\n",
    "    name_map = {1:\"Yes\", 0:\"No\"}\n",
    "    traces = []\n",
    "    for flag in df[hue].unique():\n",
    "        traces.append(\n",
    "            go.Scatter(\n",
    "                x=df[df[hue]==flag][x],\n",
    "                y=df[df[hue]==flag][y],\n",
    "                mode=mode,\n",
    "                marker=dict(color=cmap[flag]),\n",
    "                showlegend=showlegend,\n",
    "                name=name_map[flag]\n",
    "            )\n",
    "        )\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    specs=[\n",
    "                        [{}, {}],\n",
    "                        [{\"colspan\":2}, None]\n",
    "                    ],\n",
    "                    subplot_titles=(\"Amount(usd) over time\", \"Number of transactions overtime\",\n",
    "                                    \"Number of transaction by amount(usd)\")\n",
    "                   )\n",
    "\n",
    "ntraces = add_traces(df=df_,x='transaction_time',y='amount(usd)',hue='is_fraud',mode='lines',\n",
    "                    showlegend=True, cmap=['#61E50F','#D93C1D'])\n",
    "\n",
    "for trace in ntraces:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1,col=1\n",
    "    )\n",
    "    \n",
    "ntraces = add_traces(df=df_,x='transaction_time',y='transaction_id',hue='is_fraud',mode='lines',\n",
    "                    showlegend=False, cmap=['#61E50F','#D93C1D'])\n",
    "for trace in ntraces:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=1,col=2\n",
    "    )\n",
    "\n",
    "ntraces = add_traces(df=df_,x='transaction_id',y='amount(usd)',hue='is_fraud',mode='markers',\n",
    "                    showlegend=True, cmap=['#61E50F','#D93C1D'])\n",
    "for trace in ntraces:\n",
    "    fig.add_trace(\n",
    "        trace,\n",
    "        row=2,col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=780,\n",
    "                  width=960,\n",
    "                  legend=dict(title='Is fraud?'),\n",
    "                  plot_bgcolor='#fafafa',\n",
    "                  title='Overview'\n",
    "                 )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df_train.groupby(by=[pd.Grouper(key=\"transaction_time\", freq=\"1W\"),\n",
    "                           'is_fraud','category']).agg({\"amount(usd)\":'mean',\"transaction_id\":\"count\"}).reset_index()\n",
    "\n",
    "fig = px.scatter(df_,\n",
    "        x='transaction_time',\n",
    "        y='amount(usd)',\n",
    "        color='is_fraud',\n",
    "        facet_col ='category',\n",
    "        facet_col_wrap=3,\n",
    "        facet_col_spacing=.04,\n",
    "        color_discrete_map={0:'#61E50F', 1:'#D93C1D'}\n",
    ")\n",
    "\n",
    "fig.update_layout(height=1400,\n",
    "                  width=960,\n",
    "                  legend=dict(title='Is fraud?'),\n",
    "                  plot_bgcolor='#fafafa'\n",
    "                 )\n",
    "\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(showticklabels=True))\n",
    "fig.for_each_xaxis(lambda xaxis: xaxis.update(showticklabels=True, title=''))\n",
    "\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df_train.groupby(by=[pd.Grouper(key=\"transaction_time\", freq=\"1M\"),\n",
    "                           'is_fraud','category']).agg({\"amount(usd)\":'sum',\"transaction_id\":\"count\"}).reset_index()\n",
    "\n",
    "fig = px.area(\n",
    "    df_[df_.is_fraud==1],\n",
    "    x='transaction_time',\n",
    "    y='amount(usd)',\n",
    "    color='category',\n",
    "    color_discrete_sequence=px.colors.qualitative.Dark24\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600,\n",
    "                  width=960,\n",
    "                  legend=dict(title='Categories'),\n",
    "                  plot_bgcolor='#fafafa'\n",
    "                 )\n",
    "\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specified list of 12 merchants with the highest number of transactions.\n",
    "top12_merchants = df_train.merchant.value_counts()[:12]\n",
    "\n",
    "df_ = df_train.groupby(by=[pd.Grouper(key=\"transaction_time\", freq=\"1W\"),'is_fraud',\n",
    "                           'merchant']).agg({\"amount(usd)\":'mean',\"transaction_id\":\"count\"}).reset_index()\n",
    "\n",
    "df_ = df_[df_.merchant.isin(top12_merchants.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_,\n",
    "        x='transaction_time',\n",
    "        y='amount(usd)',\n",
    "        color='is_fraud',\n",
    "        facet_col ='merchant',\n",
    "        facet_col_wrap=3,\n",
    "        facet_col_spacing=.06,\n",
    "        category_orders={'merchant': top12_merchants.index}, # order the subplots\n",
    "        color_discrete_map={1:'#61E50F', 0:'#D93C1D'}\n",
    ")\n",
    "\n",
    "fig.update_layout(height=1200,\n",
    "                  width=960,\n",
    "                  title='Top 12 merchants with highest number of transactions per week',\n",
    "                  legend=dict(title='Is fraud?'),\n",
    "                  plot_bgcolor='#fafafa'\n",
    "                 )\n",
    "\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(showticklabels=True))\n",
    "fig.for_each_xaxis(lambda xaxis: xaxis.update(showticklabels=True, title=''))\n",
    "\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = ['is_fraud','job']\n",
    "df_ = df_train.groupby(by=groups).agg({\"amount(usd)\":'mean',\"transaction_id\":\"count\"}).fillna(0).reset_index()\n",
    "\n",
    "# Top 10 jobs had most fraud transactions.\n",
    "df_ = df_[df_.is_fraud==1].sort_values(by='transaction_id',\n",
    "                                       ascending=False).drop_duplicates('job', keep='first').iloc[:10, :]\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.bar(df_,\n",
    "             y='job', x='transaction_id',\n",
    "             color='amount(usd)',\n",
    "             color_continuous_scale=px.colors.sequential.Magma,\n",
    "             labels={'job':'Job title', \n",
    "                     'transaction_id': 'Number of fraud transactions'},\n",
    "             category_orders = {\"job\": df_.job.values},\n",
    "             width=960,\n",
    "             height=600)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text='Amount(usd) among top 10 jobs with the most fraud transactions'\n",
    "    ),\n",
    "    plot_bgcolor='#fafafa'\n",
    ")\n",
    "\n",
    "fig.update_coloraxes(\n",
    "    colorbar=dict(\n",
    "        title='Amount(usd) of transactions',\n",
    "        orientation='h',\n",
    "        x=1\n",
    "    ),\n",
    "    reversescale=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "groups = ['credit_card_number']\n",
    "df_ = df_train.groupby(by=groups).agg({\"amount(usd)\":'mean',\"transaction_id\":\"count\"}).fillna(0).reset_index()\n",
    "df_.sort_values('transaction_id', ascending=False, inplace=True)\n",
    "df_ = df_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df_train[df_train.is_fraud==1].groupby(by='hour_of_day').agg({'transaction_id':'count'}).reset_index()\n",
    "\n",
    "fig = px.bar(data_frame=df_,\n",
    "       x='hour_of_day',\n",
    "       y='transaction_id',\n",
    "       labels={'transaction_id':'Number of transaction'})\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text='Number of FRAUD transactions by hours of day'\n",
    "    ),\n",
    "    plot_bgcolor='#fafafa'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(type='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_cols = df_train.select_dtypes(include=['float64', 'int64', 'category']).columns\n",
    "\n",
    "# Create a new DataFrame with only the numerical columns\n",
    "df_numerical = df_train[numerical_cols]\n",
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(18, 9))\n",
    "mask = np.triu(np.ones_like(df_numerical.corr()))\n",
    "sns.heatmap(df_numerical.corr(), mask=mask, cmap='coolwarm', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, build the model to predict Fraud Transactions(label \"1\")   \n",
    "Target: The higher **F1-Score** for label 1, the better the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = ['transaction_id', 'hour_of_day', 'category', 'amount(usd)', 'merchant', 'job']\n",
    "\n",
    "#\n",
    "X = df_train[features].set_index(\"transaction_id\")\n",
    "y = df_train['is_fraud']\n",
    "\n",
    "print('X shape:{}\\ny shape:{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder(dtype=np.int64)\n",
    "enc.fit(X.loc[:,['category','merchant','job']])\n",
    "\n",
    "X.loc[:, ['category','merchant','job']] = enc.transform(X[['category','merchant','job']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X[['category','merchant','job']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "print('X_train shape:{}\\ny_train shape:{}'.format(X_train.shape,y_train.shape))\n",
    "print('X_test shape:{}\\ny_test shape:{}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dcstree = DecisionTreeClassifier(random_state=42)\n",
    "dcstree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dcstree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "cfs_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cfs_matrix, cmap='viridis', annot=True, fmt='d', annot_kws=dict(fontsize=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With DecisionTree we have F1-Score = **0.69** for label 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy={1:48050}, random_state=42)\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train.astype('float'), y_train)\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "print(\"After SMOTE:\", Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class test_model:\n",
    "    from sklearn.metrics import classification_report\n",
    "    def __init__(self):\n",
    "        self.metrics = ['prfs','auc','acc']\n",
    "\n",
    "    def fit_predict(model, X_train, X_test, y_train, y_test):\n",
    "        model = model\n",
    "        model.fit(X_train, y_train) #Fit data to model\n",
    "        y_pred = model.predict(X_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def evaluate(y_pred, metrics):\n",
    "        results = {}\n",
    "        for metric in metrics:\n",
    "            if metric == 'prfs':\n",
    "                prfs = classification_report(y_test, y_pred)\n",
    "                results['prfs'] = prfs\n",
    "            elif metric =='auc':\n",
    "                auc_score = roc_auc_score(y_test, y_pred)\n",
    "                results['auc'] = auc_score\n",
    "            elif metric =='acc':\n",
    "                results['acc'] = accuracy_score(y_test, y_pred)\n",
    "            else:\n",
    "                print('Not available metric!')\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the relevant columns\n",
    "relevant_columns = ['category', 'amount(usd)', 'gender', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long', 'is_fraud', 'hour_of_day']\n",
    "df = df_train[relevant_columns]\n",
    "\n",
    "# Encode categorical features using label encoding\n",
    "categorical_columns = ['category', 'gender', 'city', 'state', 'hour_of_day']\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances based on Gini impurity\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Select the top 15 features\n",
    "top_features = feature_importances.head(15)\n",
    "\n",
    "# Display the feature importances\n",
    "print(\"Feature Importance (Gini Impurity):\")\n",
    "print(top_features)\n",
    "\n",
    "# Create a bar plot of feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Features by Gini Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with feature names and their corresponding importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=True)\n",
    "\n",
    "# Display the feature importances\n",
    "print(\"Feature Importance (Gini Impurity):\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Create a vertical bar plot of feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(feature_importances['Feature'], feature_importances['Importance'])\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Gini Importance')\n",
    "plt.title('Feature Importance based on Gini Impurity')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Specify your metric here\n",
    "metrics = ['prfs']\n",
    "print(\"\")\n",
    "RDForest_eval = test_model.evaluate(y_pred=test_model.fit_predict(RandomForestClassifier(random_state=42),\n",
    "                                                                  X_train_smote,\n",
    "                                                                  X_test,\n",
    "                                                                  y_train_smote,\n",
    "                                                                  y_test\n",
    "                                                                 ),\n",
    "                                    metrics=metrics\n",
    "                                    )\n",
    "\n",
    "print(\"Random Forest model evaluate:\\n\", RDForest_eval['prfs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Calculate the number of samples for 2% of the dataset\n",
    "sample_size = int(len(df) * 0.02)\n",
    "\n",
    "# Randomly sample 2% of the dataset\n",
    "df_sample = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Split the sampled dataset into features (X) and target (y)\n",
    "X = df_sample.drop('is_fraud', axis=1)\n",
    "y = df_sample['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importances['Feature'], feature_importances['Importance'])\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RandomForestClassifier we have better **F1-Score = 0.76** for label 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try tuning some important Hyperparameters for RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Select the relevant columns\n",
    "relevant_columns = ['category', 'amount(usd)', 'gender', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long', 'is_fraud', 'hour_of_day']\n",
    "df = df[relevant_columns]\n",
    "\n",
    "# Calculate the number of samples for 2% of the datasetd\n",
    "df_sample = df\n",
    "\n",
    "# Encode categorical features using label encoding\n",
    "categorical_columns = ['category', 'gender', 'city', 'state', 'hour_of_day']\n",
    "for col in categorical_columns:\n",
    "    df_sample[col] = df_sample[col].astype('category').cat.codes\n",
    "\n",
    "# Split the sampled dataset into features (X) and target (y)\n",
    "X = df_sample.drop('is_fraud', axis=1)\n",
    "y = df_sample['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances based on Gini impurity\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding importances\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Select the top 15 features\n",
    "top_features = feature_importances.head(15)\n",
    "\n",
    "# Display the feature importances\n",
    "print(\"Feature Importance (Gini Impurity):\")\n",
    "print(top_features)\n",
    "\n",
    "# Create a bar plot of feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'])\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 15 Features by Gini Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 817870,
     "sourceId": 1399887,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
